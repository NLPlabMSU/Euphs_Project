{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "011e306d-2c12-47f1-a7e2-ddcfd25edda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92d75c3e-3f49-4de6-b97b-56c9909c4e23",
   "metadata": {},
   "source": [
    "If it helps, I've also used pandas's sample() (you can do a specific number, e.g. sample(n=500) or a proportionm e.g. sample(frac=0.5)) and also drop() to remove the sampled df from some starting df\n",
    "\n",
    "sampled_df = orig_df.sample(frac=0.5)\n",
    "orig_df = orig_df.drop(sampled_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ad373-e17e-4603-8c85-9bd133d6626d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### adding euph status column if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169edc19-d806-4ebe-adf5-df84b34043c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = pd.read_csv(\"turkish_dataset_2024_pre.csv\")\n",
    "df = pd.DataFrame(csvFile)\n",
    "freq = df['PET'].value_counts()\n",
    "\n",
    "pets = (set(df['PET']))\n",
    "\n",
    "df['euph_status'] = None\n",
    "\n",
    "### initializing the euph_status # DO NOT TOUCH ####################\n",
    "for pet in pets:\n",
    "    examples = df[df['PET'] == pet]\n",
    "    examples_index = df['PET'] == pet\n",
    "    avg_label = examples['label'].mean()\n",
    "    if avg_label == 1:\n",
    "        df.loc[examples_index,'euph_status'] = 'always_euph'\n",
    "    else:\n",
    "        df.loc[examples_index,'euph_status'] = 'sometimes_euph'\n",
    "#####################################################################\n",
    "\n",
    "df.to_csv(\"turkish_combined_2024.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be71cba-39d6-4874-997e-6ca633f821e3",
   "metadata": {},
   "source": [
    "### sometimes euph in both train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1024faba-8251-4f9c-9994-703eed678150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "langs = ['turkish'] # ['chinese', 'english', 'spanish', 'yoruba', 'turkish']\n",
    "number_sets = 20\n",
    "\n",
    "\n",
    "for language in langs:\n",
    "    main_folder = f\"zero_shot {language} {datetime.today().date()}\"\n",
    "    if not os.path.exists(main_folder):\n",
    "        os.makedirs(main_folder)\n",
    "    \n",
    "    for number in range(number_sets):\n",
    "        csvFile = pd.read_csv(f\"{language}_combined_2024.csv\")\n",
    "        df = pd.DataFrame(csvFile)\n",
    "        freq = df['PET'].value_counts()\n",
    "\n",
    "        train_data = .8 * len(df)\n",
    "        val_data = .1 * len(df)\n",
    "        test_data = .1 * len(df)\n",
    "    \n",
    "        pets = (set(df['PET']))\n",
    "    \n",
    "        df['euph_status'] = None\n",
    "    \n",
    "        ### initializing the euph_status # DO NOT TOUCH ####################\n",
    "        for pet in pets:\n",
    "            examples = df[df['PET'] == pet]\n",
    "            examples_index = df['PET'] == pet\n",
    "            avg_label = examples['label'].mean()\n",
    "            if avg_label == 1:\n",
    "                df.loc[examples_index,'euph_status'] = 'always_euph'\n",
    "            else:\n",
    "                df.loc[examples_index,'euph_status'] = 'sometimes_euph'\n",
    "        #####################################################################\n",
    "        \n",
    "        SE_examples = df[df['euph_status'] == 'sometimes_euph']\n",
    "        AE_examples = df[df['euph_status'] == 'always_euph']\n",
    "        AE_pets = sorted(set(AE_examples['PET']))\n",
    "        \n",
    "        temp_df = SE_examples.sample(frac = 0.9)\n",
    "        SE_examples = SE_examples.drop(temp_df.index)\n",
    "\n",
    "        test_df = SE_examples.sample(frac = 1.0)\n",
    "        SE_examples = SE_examples.drop(test_df.index)\n",
    "        \n",
    "        random.shuffle(AE_pets)\n",
    "\n",
    "        for pet in AE_pets:\n",
    "            this_pet = AE_examples[AE_examples['PET'] == pet]\n",
    "            if len(temp_df) <= train_data + val_data:\n",
    "                temp_df = pd.concat([temp_df, this_pet])\n",
    "                \n",
    "            elif len(test_df) <= test_data:\n",
    "                test_df = pd.concat([test_df, this_pet])\n",
    "              \n",
    "        # ## FOR CREATING THE DF, DO NOT TOUCH ###############################\n",
    "        \n",
    "        if language == 'chinese':\n",
    "             index = 0\n",
    "        if language == 'english':\n",
    "             index = 20\n",
    "        if language == 'spanish':\n",
    "             index = 40    \n",
    "        if language == 'yoruba':\n",
    "             index = 60\n",
    "        if language == 'turkish':\n",
    "             index = 80\n",
    "        if language == 'polish':\n",
    "            index = 100\n",
    "        if language == 'ukrainian':\n",
    "            index = 120\n",
    "    \n",
    "        train_df, val_df = train_test_split(temp_df, test_size=0.1111)\n",
    "                \n",
    "        trainName = os.path.join(main_folder, f\"train_{number + index}.csv\")\n",
    "        valName = os.path.join(main_folder, f\"val_{number + index}.csv\")\n",
    "        testName = os.path.join(main_folder, f\"test_{number}_{language}.csv\")\n",
    "    \n",
    "        train_df.to_csv(trainName)\n",
    "        val_df.to_csv(valName)\n",
    "        test_df.to_csv(testName)\n",
    "\n",
    "        # ##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47345eb7-54a5-4dc7-ba96-90cda2543a47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### sometimes euph can be in both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f92b13-f1a6-4b98-ba9d-3a3fca1787b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m langs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchinese\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspanish\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myoruba\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m langs:\n\u001b[1;32m----> 5\u001b[0m     csvFile \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_combined_2024.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(csvFile)\n\u001b[0;32m      7\u001b[0m     freq \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPET\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "langs = ['chinese', 'english', 'spanish', 'yoruba']\n",
    "\n",
    "for language in langs:\n",
    "    csvFile = pd.read_csv(f\"{language}_combined_2024.csv\")\n",
    "    df = pd.DataFrame(csvFile)\n",
    "    freq = df['PET'].value_counts()\n",
    "    \n",
    "    train_data = .8 * len(df)\n",
    "    val_data = .1 * len(df)\n",
    "    test_data = .1 * len(df)\n",
    "\n",
    "    pets = sorted(set(df['PET']))\n",
    "\n",
    "    df['euph_status'] = None\n",
    "\n",
    "    \n",
    "    for pet in pets:\n",
    "        examples = df[df['PET'] == pet]\n",
    "        examples_index = df['PET'] == pet\n",
    "        avg_label = examples['label'].mean()\n",
    "        if avg_label == 1:\n",
    "            df.loc[examples_index,'euph_status'] = 'always_euph'\n",
    "        else:\n",
    "            df.loc[examples_index,'euph_status'] = 'sometimes_euph'\n",
    "            \n",
    "    number_sets = 20\n",
    "    main_folder = f\"zero_shot {language} {datetime.today().date()}\"\n",
    "    \n",
    "    if not os.path.exists(main_folder):\n",
    "        os.makedirs(main_folder)\n",
    "    \n",
    "    for number in range(number_sets):\n",
    "        list_train = []\n",
    "        list_val = []\n",
    "        list_test = []\n",
    "        random.shuffle(pets)\n",
    "    \n",
    "        for pet in pets:\n",
    "            examples = df[df['PET'] == pet]\n",
    "            list_examples = examples.values.tolist()\n",
    "            examples_index = df['PET'] == pet\n",
    "            if df.loc[examples_index,'euph_status'].all() == 'always_euph':\n",
    "                status = 'always'\n",
    "            else:\n",
    "                status = 'sometimes'\n",
    "    \n",
    "            if status == 'sometimes':\n",
    "                  for i in range(len(list_examples)):\n",
    "                    if len(list_train) <= train_data + val_data:\n",
    "                        list_train.append(list_examples[i])\n",
    "                    elif len(list_test) <= test_data:\n",
    "                        list_test.append(list_examples[i])\n",
    "            else:\n",
    "                if len(list_train) <= train_data + val_data:\n",
    "                    for i in range(len(list_examples)):\n",
    "                        list_train.append(list_examples[i])\n",
    "                elif len(list_test) <= test_data:\n",
    "                    for i in range(len(list_examples)):\n",
    "                        list_test.append(list_examples[i])\n",
    "              \n",
    "    \n",
    "        if language == 'chinese':\n",
    "            index = 0\n",
    "            temp_df = pd.DataFrame(list_train, columns = ['index', 'orig_text', 'label', 'pet', 'text', 'euph_status'])\n",
    "            dataframe_test = pd.DataFrame(list_test, columns = ['index', 'orig_text', 'label', 'pet', 'text', 'euph_status'])\n",
    "    \n",
    "        if language == 'english':\n",
    "            index = 20\n",
    "            temp_df = pd.DataFrame(list_train, columns = ['index', 'text', 'label', 'category', 'pet', 'euph_status', 'sentence', 'orig_text'])\n",
    "            dataframe_test = pd.DataFrame(list_test, columns = ['index', 'text', 'label', 'category', 'pet', 'euph_status', 'sentence', 'orig_text'])\n",
    "\n",
    "        if language == 'spanish':\n",
    "            index = 40\n",
    "            temp_df = pd.DataFrame(list_train, columns = ['index', 'PET', 'text', 'label', 'category', 'source', 'bibliography', 'country', 'euph_status'])\n",
    "            dataframe_test = pd.DataFrame(list_test, columns = ['index', 'PET', 'text', 'label', 'category', 'source', 'bibliography', 'country', 'euph_status'])\n",
    "\n",
    "        if language == 'yoruba':\n",
    "            index = 60\n",
    "            temp_df = pd.DataFrame(list_train, columns = ['index', 'PET', 'literal translation', 'euphemistic meanings', 'category', 'label', 'text', 'source', 'contains_boundary_tokens', 'euph_status'])\n",
    "            dataframe_test = pd.DataFrame(list_test, columns = ['index', 'PET', 'literal translation', 'euphemistic meanings', 'category', 'label', 'text', 'source', 'contains_boundary_tokens', 'euph_status'])\n",
    "\n",
    "        \n",
    "        dataframe_train, dataframe_val = train_test_split(temp_df, test_size=0.1111)\n",
    "        \n",
    "        print(len(dataframe_train), len(dataframe_val), len(dataframe_test))\n",
    "    \n",
    "        \n",
    "        trainName = os.path.join(main_folder, f\"train_{number + index}.csv\")\n",
    "        valName = os.path.join(main_folder, f\"val_{number + index}.csv\")\n",
    "        testName = os.path.join(main_folder, f\"test_{number}_{language}.csv\")\n",
    "    \n",
    "        dataframe_train.to_csv(trainName)\n",
    "        dataframe_val.to_csv(valName)\n",
    "        dataframe_test.to_csv(testName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4c5fa-fa17-4620-880f-d0561a4f5252",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### train and val NO OVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40c7fa-ec0f-4c8a-9116-1b373c8e7155",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_sets = int(input())\n",
    "\n",
    "main_folder = f\"zero_shot {language} {datetime.today().date()}\"\n",
    "\n",
    "if not os.path.exists(main_folder):\n",
    "    os.makedirs(main_folder)\n",
    "\n",
    "for number in range(number_sets):\n",
    "    list_train = []\n",
    "    list_eval = []\n",
    "    list_test = []\n",
    "    random.shuffle(pets)\n",
    "\n",
    "    for word in pets:\n",
    "        examples = df[df['PET'] == word] \n",
    "        list_examples = examples.values.tolist()\n",
    "        \n",
    "        if len(list_train) <= train_data:\n",
    "            for i in range(len(list_examples)):\n",
    "                list_train.append(list_examples[i])\n",
    "        elif len(list_eval) <= eval_data:\n",
    "            for i in range(len(list_examples)):\n",
    "                list_eval.append(list_examples[i])\n",
    "        elif len(list_test) <= test_data:\n",
    "            for i in range(len(list_examples)):\n",
    "                list_test.append(list_examples[i])\n",
    "\n",
    "    \n",
    "    print(len(list_train), len(list_eval), len(list_test))\n",
    "\n",
    "    \n",
    "    # # chinese\n",
    "    # dataframe_train = pd.DataFrame(list_train, columns = ['index', 'orig_text', 'label', 'pet', 'text'])\n",
    "    # dataframe_eval = pd.DataFrame(list_eval, columns = ['index', 'orig_text', 'label', 'pet', 'text'])\n",
    "    # dataframe_test = pd.DataFrame(list_test, columns = ['index', 'orig_text', 'label', 'pet', 'text'])\n",
    "\n",
    "    # # english\n",
    "    # dataframe_train = pd.DataFrame(list_train, columns = ['index', 'text', 'label', 'category', 'pet', 'euph_status', 'sentence'])\n",
    "    # dataframe_eval = pd.DataFrame(list_eval, columns = ['index', 'text', 'label', 'category',  'pet','euph_status', 'sentence'])\n",
    "    # dataframe_test = pd.DataFrame(list_test, columns = ['index', 'text', 'label', 'category', 'pet', 'euph_status', 'sentence'])\n",
    "\n",
    "    # # spanish\n",
    "    # dataframe_train = pd.DataFrame(list_train, columns = ['index', 'PET', 'text', 'label', 'category', 'source', 'bibliography', 'country'])\n",
    "    # dataframe_eval = pd.DataFrame(list_eval, columns = ['index', 'PET', 'text', 'label', 'category', 'source', 'bibliography', 'country'])\n",
    "    # dataframe_test = pd.DataFrame(list_test, columns = ['index', 'PET', 'text', 'label', 'category', 'source', 'bibliography', 'country'])\n",
    "\n",
    "    # yoruba\n",
    "    dataframe_train = pd.DataFrame(list_train, columns = ['index', 'PET', 'literal translation', 'euphemistic meanings', 'category', 'label', 'text', 'source', 'contains_boundary_tokens', 'multiple_boundary_tokens'])\n",
    "    dataframe_eval = pd.DataFrame(list_eval, columns = ['index', 'PET', 'literal translation', 'euphemistic meanings', 'category', 'label', 'text', 'source', 'contains_boundary_tokens', 'multiple_boundary_tokens'])\n",
    "    dataframe_test = pd.DataFrame(list_test, columns = ['index', 'PET', 'literal translation', 'euphemistic meanings', 'category', 'label', 'text', 'source', 'contains_boundary_tokens', 'multiple_boundary_tokens'])\n",
    "\n",
    "    \n",
    "    trainName = os.path.join(main_folder, f\"train_{number + 60}.csv\")\n",
    "    evalName = os.path.join(main_folder, f\"val_{number + 60}.csv\")\n",
    "    testName = os.path.join(main_folder, f\"test_{number}_{language}.csv\")\n",
    "\n",
    "    dataframe_train.to_csv(trainName)\n",
    "    dataframe_eval.to_csv(evalName)\n",
    "    dataframe_test.to_csv(testName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a9810-66fc-4ccb-ba46-e9282ac53fcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### for train/val sets to have overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca40f593-18ba-4007-a700-d7a9f1bd773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "number_sets = int(input())\n",
    "\n",
    "main_folder = f\"zero_shot {language} {datetime.today().date()}\"\n",
    "\n",
    "if not os.path.exists(main_folder):\n",
    "    os.makedirs(main_folder)\n",
    "\n",
    "for number in range(number_sets):\n",
    "    list_train = []\n",
    "    list_val = []\n",
    "    list_test = []\n",
    "    random.shuffle(pets)\n",
    "\n",
    "    for word in pets:\n",
    "        examples = df[df['PET'] == word] \n",
    "        list_examples = examples.values.tolist()\n",
    "        \n",
    "        if len(list_train) <= train_data + val_data:\n",
    "            for i in range(len(list_examples)):\n",
    "                list_train.append(list_examples[i])\n",
    "        elif len(list_test) <= test_data:\n",
    "            for i in range(len(list_examples)):\n",
    "                list_test.append(list_examples[i])\n",
    "                \n",
    "\n",
    "    \n",
    "    if language == 'chinese':\n",
    "        temp_df = pd.DataFrame(list_train, columns = ['index', 'orig_text', 'label', 'pet', 'text'])\n",
    "        dataframe_test = pd.DataFrame(list_test, columns = ['index', 'orig_text', 'label', 'pet', 'text'])\n",
    "\n",
    "    if language == 'english':\n",
    "        temp_df = pd.DataFrame(list_train, columns = ['index', 'text', 'label', 'category', 'pet', 'euph_status', 'sentence'])\n",
    "        dataframe_test = pd.DataFrame(list_test, columns = ['index', 'text', 'label', 'category', 'pet', 'euph_status', 'sentence'])\n",
    "\n",
    "    if language == 'spanish':\n",
    "        temp_df = pd.DataFrame(list_train, columns = ['index', 'PET', 'text', 'label', 'category', 'source', 'bibliography', 'country'])\n",
    "        dataframe_test = pd.DataFrame(list_test, columns = ['index', 'PET', 'text', 'label', 'category', 'source', 'bibliography', 'country'])\n",
    "\n",
    "    if language == 'yoruba':\n",
    "        temp_df = pd.DataFrame(list_train, columns = ['index', 'PET', 'literal translation', 'euphemistic meanings', 'category', 'label', 'text', 'source', 'contains_boundary_tokens', 'multiple_boundary_tokens'])\n",
    "        dataframe_test = pd.DataFrame(list_test, columns = ['index', 'PET', 'literal translation', 'euphemistic meanings', 'category', 'label', 'text', 'source', 'contains_boundary_tokens', 'multiple_boundary_tokens'])\n",
    "\n",
    "    dataframe_train, dataframe_val = train_test_split(temp_df, test_size=0.1111)\n",
    "    \n",
    "    print(len(dataframe_train), len(dataframe_val), len(dataframe_test))\n",
    "\n",
    "    \n",
    "    trainName = os.path.join(main_folder, f\"train_{number + 60}.csv\")\n",
    "    valName = os.path.join(main_folder, f\"val_{number + 60}.csv\")\n",
    "    testName = os.path.join(main_folder, f\"test_{number}_{language}.csv\")\n",
    "\n",
    "    dataframe_train.to_csv(trainName)\n",
    "    dataframe_val.to_csv(valName)\n",
    "    dataframe_test.to_csv(testName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77c07aac-4bba-4a0f-9535-758489536d22",
   "metadata": {},
   "source": [
    "number_sets = int(input())\n",
    "\n",
    "main_folder = f\"zero_shot {language} {datetime.today().date()}\"\n",
    "\n",
    "if not os.path.exists(main_folder):\n",
    "    os.makedirs(main_folder)\n",
    "\n",
    "for number in range(number_sets):\n",
    "    list_train = []\n",
    "    list_eval = []\n",
    "    list_test = []\n",
    "    random.shuffle(pets)\n",
    "\n",
    "    for word in pets:\n",
    "        examples = df[df['PET'] == word] \n",
    "        list_examples = examples.values.tolist()\n",
    "        \n",
    "        if len(list_train) <= train_data:\n",
    "            for i in range(len(list_examples)):\n",
    "                list_train.append(list_examples[i])\n",
    "        elif len(list_eval) <= eval_data:\n",
    "            for i in range(len(list_examples)):\n",
    "                list_eval.append(list_examples[i])\n",
    "        elif len(list_test) <= test_data:\n",
    "            for i in range(len(list_examples)):\n",
    "                list_test.append(list_examples[i])\n",
    "\n",
    "    \n",
    "    print(len(list_train), len(list_eval), len(list_test))\n",
    "    \n",
    "\n",
    "    \n",
    "    subfolder = f\"subfolder_{number}\"\n",
    "    \n",
    "    subfolder_path = os.path.join(main_folder, subfolder)\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        os.makedirs(subfolder_path)\n",
    "\n",
    "    dataframe_train = pd.DataFrame(list_train, columns = ['index','text', 'label', 'category', 'PET', 'euph_status', 'sentence'])\n",
    "    dataframe_eval = pd.DataFrame(list_eval, columns = ['index','text', 'label', 'category', 'PET', 'euph_status', 'sentence'])\n",
    "    dataframe_test = pd.DataFrame(list_test, columns = ['index','text', 'label', 'category', 'PET', 'euph_status', 'sentence'])\n",
    "    \n",
    "    trainName = os.path.join(subfolder_path, f\"train_{number}.csv\")\n",
    "    evalName = os.path.join(subfolder_path, f\"val_{number}.csv\")\n",
    "    testName = os.path.join(subfolder_path, f\"test_{number}_{language}.csv\")\n",
    "\n",
    "    dataframe_train.to_csv(trainName)\n",
    "    dataframe_eval.to_csv(evalName)\n",
    "    dataframe_test.to_csv(testName)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
